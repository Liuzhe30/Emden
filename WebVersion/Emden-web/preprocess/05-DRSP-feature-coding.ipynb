{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### generate DRSP test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate feature dataset\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxasa_dict = {\n",
    "'C':167, 'D':193, 'S':155, 'Q':225, 'K':236,\n",
    "'I':197, 'P':159, 'T':172, 'F':240, 'N':195,\n",
    "'G':104, 'H':224, 'L':201, 'R':274, 'W':285,\n",
    "'A':129, 'V':174, 'E':223, 'Y':263, 'M':224\n",
    "}\n",
    "\n",
    "eyes = np.eye(3)\n",
    "ss_dict = {\n",
    "'H':eyes[0],'G':eyes[0],'I':eyes[0],\n",
    "'B':eyes[1],'E':eyes[1],\n",
    "'T':eyes[2]\n",
    "}\n",
    "\n",
    "rootpath = '../datasets/DRSP/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate rASA and padding\n",
    "pdb_name_list = os.listdir(rootpath + 'AF2pdb/')\n",
    "pdb_name_list = [x.split('.')[0] for x in pdb_name_list]\n",
    "\n",
    "zero_list = []\n",
    "for pdb in pdb_name_list:\n",
    "    try:\n",
    "        with open(rootpath + 'fasta/' + pdb +'.fasta') as file:\n",
    "            fasta_file = file.readlines()\n",
    "            fasta_len = len(fasta_file[1])\n",
    "        if(pdb in zero_list): # large protein\n",
    "            ss_matrix = np.zeros([fasta_len, 3], int)\n",
    "            with open(rootpath + 'SS/' + pdb + '.ss','w+') as out_file:\n",
    "                np.savetxt(out_file, ss_matrix, fmt='%.1f')\n",
    "            rasa_matrix = np.zeros([fasta_len, 1], float)\n",
    "            with open(rootpath + 'rASA/' + pdb + '.rasa','w+') as out_file:\n",
    "                np.savetxt(out_file, rasa_matrix, fmt='%.3f')\n",
    "        else:\n",
    "            ss_matrix = np.zeros([fasta_len, 3], int)\n",
    "            rasa_matrix = np.zeros([fasta_len, 1], float)\n",
    "            with open(rootpath + 'dssp/' + pdb +'.dssp') as dssp_file:\n",
    "                line = dssp_file.readline()\n",
    "                while line:\n",
    "                    if(line.split()[0] == '#'):\n",
    "                        break\n",
    "                    line = dssp_file.readline()\n",
    "                line = dssp_file.readline()\n",
    "                index = 0\n",
    "                while line:\n",
    "                    if(len(line.split()) > 0):\n",
    "                        SS = line[16]\n",
    "                        ACC = int(line[35:38].strip())\n",
    "                        AA = line[13]\n",
    "                        # check ss\n",
    "                        if(SS != ' '):\n",
    "                            if(SS not in ss_dict.keys()):\n",
    "                                ss_matrix[index][0:3] = eyes[2]\n",
    "                            else:\n",
    "                                ss_matrix[index][0:3] = ss_dict[SS]\n",
    "                        # check rasa\n",
    "                        rasa_matrix[index][0] = float(ACC)/maxasa_dict[AA]\n",
    "                        index += 1                    \n",
    "                    line = dssp_file.readline()\n",
    "            with open(rootpath + 'SS/' + pdb + '.ss','w+') as out_file:\n",
    "                np.savetxt(out_file, ss_matrix, fmt='%.1f')\n",
    "            with open(rootpath + 'rASA/' + pdb + '.rasa','w+') as out_file:\n",
    "                np.savetxt(out_file, rasa_matrix, fmt='%.3f')\n",
    "    except IndexError:\n",
    "        print(pdb)\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:04<00:00,  1.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      drugname                                              smile  \\\n",
      "0  vemurafenib  CCCS(=O)(=O)NC1=C(C(=C(C=C1)F)C(=O)C2=CNC3=C2C...   \n",
      "1    PD0325901  C1=CC(=C(C=C1I)F)NC2=C(C=CC(=C2F)F)C(=O)NOC[C@...   \n",
      "2   crizotinib  C[C@H](C1=C(C=CC(=C1Cl)F)Cl)OC2=C(N=CC(=C2)C3=...   \n",
      "\n",
      "  molecular_weight molecular_formula  \\\n",
      "0            489.9   C23H18ClF2N3O3S   \n",
      "1           482.19     C16H14F3IN2O4   \n",
      "2            450.3     C21H22Cl2FN5O   \n",
      "\n",
      "                                                atom  \\\n",
      "0  [Atom(1, Cl), Atom(2, S), Atom(3, F), Atom(4, ...   \n",
      "1  [Atom(1, I), Atom(2, F), Atom(3, F), Atom(4, F...   \n",
      "2  [Atom(1, Cl), Atom(2, Cl), Atom(3, F), Atom(4,...   \n",
      "\n",
      "                                         fingerprint  \\\n",
      "0  00000371E07B3180440000000000000000000000000160...   \n",
      "1  00000371C07B3980000200000000000000000000000000...   \n",
      "2  00000371E07BA100060000000000000000000000000160...   \n",
      "\n",
      "                                  cactvs_fingerprint  \n",
      "0  1110000001111011001100011000000001000100000000...  \n",
      "1  1100000001111011001110011000000000000000000000...  \n",
      "2  1110000001111011101000010000000000000110000000...  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# mapping pubchem fingerprint\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import pubchempy as pcp\n",
    "from tqdm import tqdm\n",
    "\n",
    "new_drug_table = pd.DataFrame(columns=['drugname', 'smile', 'molecular_weight', 'molecular_formula', 'atom', 'fingerprint', 'cactvs_fingerprint'])\n",
    "drug_name_list = ['vemurafenib', 'PD0325901', 'crizotinib']\n",
    "for i in tqdm(range(3)):\n",
    "    drugname = drug_name_list[i]\n",
    "    compound = pcp.get_compounds(drugname,'name')[0]\n",
    "    try:\n",
    "        smile = compound.isomeric_smiles\n",
    "    except AttributeError:\n",
    "        smile = np.nan\n",
    "    try:\n",
    "        molecular_weight = compound.molecular_weight\n",
    "    except AttributeError:\n",
    "        molecular_weight = np.nan   \n",
    "    try:\n",
    "        molecular_formula = compound.molecular_formula\n",
    "    except AttributeError:\n",
    "        molecular_formula = np.nan\n",
    "    try: \n",
    "        atom = compound.atoms\n",
    "    except AttributeError:\n",
    "        atom = np.nan\n",
    "    try:\n",
    "        fingerprint = compound.fingerprint\n",
    "    except AttributeError:\n",
    "        fingerprint = np.nan\n",
    "    try:\n",
    "        cactvs_fingerprint = compound.cactvs_fingerprint\n",
    "    except AttributeError:\n",
    "        cactvs_fingerprint = np.nan\n",
    "    new_drug_table = new_drug_table.append([{'drugname':drugname, 'smile':smile, 'molecular_weight':molecular_weight, 'molecular_formula':molecular_formula, \n",
    "                                    'atom':atom, 'fingerprint':fingerprint, 'cactvs_fingerprint':cactvs_fingerprint}], ignore_index=True)\n",
    "print(new_drug_table)\n",
    "new_drug_table.to_csv(rootpath + 'drsp_drug_table_fpfixed.csv', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 56.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      drugname                                              smile  \\\n",
      "0  vemurafenib  CCCS(=O)(=O)NC1=C(C(=C(C=C1)F)C(=O)C2=CNC3=C2C...   \n",
      "1    PD0325901  C1=CC(=C(C=C1I)F)NC2=C(C=CC(=C2F)F)C(=O)NOC[C@...   \n",
      "2   crizotinib  C[C@H](C1=C(C=CC(=C1Cl)F)Cl)OC2=C(N=CC(=C2)C3=...   \n",
      "\n",
      "   molecular_weight molecular_formula  \\\n",
      "0            489.90   C23H18ClF2N3O3S   \n",
      "1            482.19     C16H14F3IN2O4   \n",
      "2            450.30     C21H22Cl2FN5O   \n",
      "\n",
      "                                                atom  \\\n",
      "0  [Atom(1, Cl), Atom(2, S), Atom(3, F), Atom(4, ...   \n",
      "1  [Atom(1, I), Atom(2, F), Atom(3, F), Atom(4, F...   \n",
      "2  [Atom(1, Cl), Atom(2, Cl), Atom(3, F), Atom(4,...   \n",
      "\n",
      "                                         fingerprint  \\\n",
      "0  00000371E07B3180440000000000000000000000000160...   \n",
      "1  00000371C07B3980000200000000000000000000000000...   \n",
      "2  00000371E07BA100060000000000000000000000000160...   \n",
      "\n",
      "                                  cactvs_fingerprint  \\\n",
      "0  1110000001111011001100011000000001000100000000...   \n",
      "1  1100000001111011001110011000000000000000000000...   \n",
      "2  1110000001111011101000010000000000000110000000...   \n",
      "\n",
      "                                         smile_array  \n",
      "0  [42, 42, 42, 49, 1, 40, 48, 31, 1, 40, 48, 31,...  \n",
      "1  [42, 35, 40, 42, 42, 1, 40, 42, 1, 42, 40, 42,...  \n",
      "2  [42, 53, 42, 8, 12, 54, 1, 42, 35, 40, 42, 1, ...  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# smile dict from DeepDTA (source: https://github.com/hkmztrk/DeepDTA/blob/master/source/datahelper.py)\n",
    "CHARISOSMISET = {\"#\": 29, \"%\": 30, \")\": 31, \"(\": 1, \"+\": 32, \"-\": 33, \"/\": 34, \".\": 2, \n",
    "\t\t\t\t\"1\": 35, \"0\": 3, \"3\": 36, \"2\": 4, \"5\": 37, \"4\": 5, \"7\": 38, \"6\": 6, \n",
    "\t\t\t\t\"9\": 39, \"8\": 7, \"=\": 40, \"A\": 41, \"@\": 8, \"C\": 42, \"B\": 9, \"E\": 43, \n",
    "\t\t\t\t\"D\": 10, \"G\": 44, \"F\": 11, \"I\": 45, \"H\": 12, \"K\": 46, \"M\": 47, \"L\": 13, \n",
    "\t\t\t\t\"O\": 48, \"N\": 14, \"P\": 15, \"S\": 49, \"R\": 16, \"U\": 50, \"T\": 17, \"W\": 51, \n",
    "\t\t\t\t\"V\": 18, \"Y\": 52, \"[\": 53, \"Z\": 19, \"]\": 54, \"\\\\\": 20, \"a\": 55, \"c\": 56, \n",
    "\t\t\t\t\"b\": 21, \"e\": 57, \"d\": 22, \"g\": 58, \"f\": 23, \"i\": 59, \"h\": 24, \"m\": 60, \n",
    "\t\t\t\t\"l\": 25, \"o\": 61, \"n\": 26, \"s\": 62, \"r\": 27, \"u\": 63, \"t\": 28, \"y\": 64}\n",
    "\n",
    "# encode smile\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from tqdm import tqdm\n",
    "new_drug_table = pd.read_csv(rootpath + 'drsp_drug_table_fpfixed.csv')\n",
    "new_drug_table['smile_array'] = 0\n",
    "new_drug_table['smile_array'] = new_drug_table['smile_array'].astype(object)\n",
    "for i in tqdm(range(new_drug_table.shape[0])):\n",
    "    drugname = new_drug_table['drugname'][i]\n",
    "    smile = new_drug_table['smile'][i]\n",
    "    smile_num_list = []\n",
    "    for strr in smile:\n",
    "        smile_num_list.append(CHARISOSMISET[strr])\n",
    "    #smile_num = np.array(smile_num_list)\n",
    "    #new_drug_table['smile_array'][i] = new_drug_table['smile_array'][i].apply(lambda x: smile_num_list)\n",
    "    new_drug_table.loc[:,'smile_array'].loc[i] = np.array(smile_num_list)\n",
    "print(new_drug_table)\n",
    "new_drug_table.to_pickle(rootpath + 'drsp_drug_table_fpfixed_smilenum.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label processing\n",
    "label_list = [0, 0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# onehot coding dict\n",
    "import numpy as np\n",
    "eyes = np.eye(20)\n",
    "protein_dict = {'C':eyes[0], 'D':eyes[1], 'S':eyes[2], 'Q':eyes[3], 'K':eyes[4],\n",
    "    'I':eyes[5], 'P':eyes[6], 'T':eyes[7], 'F':eyes[8], 'N':eyes[9],\n",
    "    'G':eyes[10], 'H':eyes[11], 'L':eyes[12], 'R':eyes[13], 'W':eyes[14],\n",
    "    'A':eyes[15], 'V':eyes[16], 'E':eyes[17], 'Y':eyes[18], 'M':eyes[19]}\n",
    "fingerprint_dict = {'1':1,'0':0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature coding & dataset generate\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "window_len = 30\n",
    "\n",
    "drsp_evidence = pd.read_pickle(rootpath + 'drsp_drug_table_fpfixed_smilenum.pkl')\n",
    "dataset_feature = pd.DataFrame(columns=['gene', 'uniprotac', 'variant', 'drug', \n",
    "                                        'smile', 'smile_num' ,'cactvs_fingerprint', 'molecular_weight', # drug features\n",
    "                                        'onehot_before', 'onehot_after', 'hhm_before', 'hhm_after', 'ss', 'rasa', # sequence features\n",
    "                                        'label', 'source'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evidence 1: \n",
    "gene = 'BRAF'\n",
    "uniprotac = 'P15056'\n",
    "variant = 'L505H'\n",
    "drug = drsp_evidence['drugname'][0]\n",
    "smile = drsp_evidence['smile'][0]\n",
    "smile_num = drsp_evidence['smile_array'][0]\n",
    "cactvs_fingerprint_str = drsp_evidence['cactvs_fingerprint'][0]\n",
    "molecular_weight = drsp_evidence['molecular_weight'][0]\n",
    "source = 'DRSP'\n",
    "label = 0\n",
    "\n",
    "smile_array = np.zeros(shape=(85,))\n",
    "for j in range(min(85, smile_num.shape[0])):\n",
    "    smile_array[j] = smile_num[j]\n",
    "cactvs_fingerprint = []\n",
    "for strr in cactvs_fingerprint_str:\n",
    "    cactvs_fingerprint.append(fingerprint_dict[strr])\n",
    "cactvs_fingerprint = np.array(cactvs_fingerprint)\n",
    "\n",
    "# sequence features from file\n",
    "pos = int(variant[1:-1])\n",
    "pos_after = variant[-1]\n",
    "\n",
    "# fasta before\n",
    "with open(rootpath + 'fasta/' + uniprotac + '.fasta') as file:\n",
    "    fasta_file = file.readlines()\n",
    "    fasta_full = fasta_file[1]\n",
    "    seq_len = len(fasta_full)\n",
    "    onehot_before = []\n",
    "    if(pos <= window_len - 1):\n",
    "        for j in range(window_len-pos+1): # padding head\n",
    "            onehot_before.append(np.zeros(20))\n",
    "        for strr in fasta_full[0:pos+window_len]:\n",
    "            onehot_before.append(protein_dict[strr])\n",
    "    elif(seq_len - pos < window_len):\n",
    "        for strr in fasta_full[pos-window_len-1:]:\n",
    "            onehot_before.append(protein_dict[strr])\n",
    "        for j in range(window_len-seq_len+pos): # padding end\n",
    "            onehot_before.append(np.zeros(20))\n",
    "    else:        \n",
    "        for strr in fasta_full[pos-window_len-1:pos+window_len]:\n",
    "            onehot_before.append(protein_dict[strr])\n",
    "onehot_before = np.array(onehot_before)\n",
    "\n",
    "# fasta after\n",
    "with open(rootpath + 'fasta/' + uniprotac + '_' + variant + '.fasta') as file:\n",
    "    fasta_file = file.readlines()\n",
    "    fasta_full = fasta_file[1]\n",
    "    #fasta_after = fasta_full[pos-window_len-1:pos+window_len]\n",
    "    onehot_after = []\n",
    "    if(pos <= window_len - 1):\n",
    "        for j in range(window_len-pos+1): # padding head\n",
    "            onehot_after.append(np.zeros(20))\n",
    "        for strr in fasta_full[0:pos+window_len]:\n",
    "            onehot_after.append(protein_dict[strr])\n",
    "    elif(seq_len - pos < window_len):\n",
    "        for strr in fasta_full[pos-window_len-1:]:\n",
    "            onehot_after.append(protein_dict[strr])\n",
    "        for j in range(window_len-seq_len+pos): # padding end\n",
    "            onehot_after.append(np.zeros(20))\n",
    "    else:        \n",
    "        for strr in fasta_full[pos-window_len-1:pos+window_len]:\n",
    "            onehot_after.append(protein_dict[strr])\n",
    "fasta_len = len(fasta_full)\n",
    "onehot_after = np.array(onehot_after)\n",
    "\n",
    "# hhm before\n",
    "with open(rootpath + 'hhm/' + uniprotac + '.hhm') as hhm_file:     \n",
    "    hhm_matrix = np.zeros([fasta_len, 30], float)\n",
    "    hhm_line = hhm_file.readline()\n",
    "    idxx = 0\n",
    "    while(hhm_line[0] != '#'):\n",
    "        hhm_line = hhm_file.readline()\n",
    "    for i in range(0,5):\n",
    "        hhm_line = hhm_file.readline()\n",
    "    while hhm_line:\n",
    "        if(len(hhm_line.split()) == 23):\n",
    "            idxx += 1\n",
    "            if(idxx == fasta_len + 1):\n",
    "                break\n",
    "            each_item = hhm_line.split()[2:22]\n",
    "            for idx, s in enumerate(each_item):\n",
    "                if(s == '*'):\n",
    "                    each_item[idx] = '99999'                            \n",
    "            for j in range(0, 20):\n",
    "                hhm_matrix[idxx - 1, j] = int(each_item[j])\n",
    "                #hhm_matrix[idxx - 1, j] = 10/(1 + math.exp(-1 * int(each_item[j])/2000))                                              \n",
    "        elif(len(hhm_line.split()) == 10):\n",
    "            each_item = hhm_line.split()[0:10]\n",
    "            for idx, s in enumerate(each_item):\n",
    "                if(s == '*'):\n",
    "                    each_item[idx] = '99999'                             \n",
    "            for j in range(20, 30):\n",
    "                hhm_matrix[idxx - 1, j] = int(each_item[j - 20]) \n",
    "                #hhm_matrix[idxx - 1, j] = 10/(1 + math.exp(-1 * int(each_item[j - 20])/2000))                                                               \n",
    "        hhm_line = hhm_file.readline()\n",
    "    if(pos <= window_len - 1):\n",
    "        padding = np.zeros(shape=[window_len-pos+1,30])\n",
    "        hhm_before_array = np.vstack((padding,hhm_matrix[0:pos+window_len, :])) \n",
    "    elif(seq_len - pos < window_len):\n",
    "        padding = np.zeros(shape=[window_len-seq_len+pos,30])\n",
    "        hhm_before_array = np.vstack((hhm_matrix[pos-window_len-1:, :],padding))\n",
    "    else:\n",
    "        hhm_before_array = hhm_matrix[pos-window_len-1:pos+window_len, :]\n",
    "    #hhm_before = hhm_before_array.tolist()\n",
    "\n",
    "# hhm after\n",
    "with open(rootpath + 'hhm/' + uniprotac + '_' + variant + '.hhm') as hhm_file:     \n",
    "    hhm_matrix = np.zeros([fasta_len, 30], float)\n",
    "    hhm_line = hhm_file.readline()\n",
    "    idxx = 0\n",
    "    while(hhm_line[0] != '#'):\n",
    "        hhm_line = hhm_file.readline()\n",
    "    for i in range(0,5):\n",
    "        hhm_line = hhm_file.readline()\n",
    "    while hhm_line:\n",
    "        if(len(hhm_line.split()) == 23):\n",
    "            idxx += 1\n",
    "            if(idxx == fasta_len + 1):\n",
    "                break\n",
    "            each_item = hhm_line.split()[2:22]\n",
    "            for idx, s in enumerate(each_item):\n",
    "                if(s == '*'):\n",
    "                    each_item[idx] = '99999'                            \n",
    "            for j in range(0, 20):\n",
    "                hhm_matrix[idxx - 1, j] = int(each_item[j])\n",
    "                #hhm_matrix[idxx - 1, j] = 10/(1 + math.exp(-1 * int(each_item[j])/2000))                                              \n",
    "        elif(len(hhm_line.split()) == 10):\n",
    "            each_item = hhm_line.split()[0:10]\n",
    "            for idx, s in enumerate(each_item):\n",
    "                if(s == '*'):\n",
    "                    each_item[idx] = '99999'                             \n",
    "            for j in range(20, 30):\n",
    "                hhm_matrix[idxx - 1, j] = int(each_item[j - 20]) \n",
    "                #hhm_matrix[idxx - 1, j] = 10/(1 + math.exp(-1 * int(each_item[j - 20])/2000))                                                                        \n",
    "        hhm_line = hhm_file.readline()\n",
    "    if(pos <= window_len - 1):\n",
    "        padding = np.zeros(shape=[window_len-pos+1,30])\n",
    "        hhm_after_array = np.vstack((padding,hhm_matrix[0:pos+window_len, :])) \n",
    "    elif(seq_len - pos < window_len):\n",
    "        padding = np.zeros(shape=[window_len-seq_len+pos,30])\n",
    "        hhm_after_array = np.vstack((hhm_matrix[pos-window_len-1:, :],padding))\n",
    "    else:\n",
    "        hhm_after_array = hhm_matrix[pos-window_len-1:pos+window_len, :]\n",
    "    #hhm_after = hhm_after_array.tolist()\n",
    "\n",
    "# rasa\n",
    "rasa_array = np.loadtxt(rootpath + 'rASA/' + uniprotac + '.rasa')\n",
    "if(pos <= window_len - 1):\n",
    "    padding = np.zeros(window_len-pos+1)\n",
    "    rasa_array = np.append(padding,rasa_array[0:pos+window_len])\n",
    "elif(seq_len - pos < window_len):\n",
    "    padding = np.zeros(window_len-seq_len+pos)\n",
    "    rasa_array = np.append(rasa_array[pos-window_len-1:],padding)\n",
    "else:\n",
    "    rasa_array = rasa_array[pos-window_len-1:pos+window_len]\n",
    "#rasa = rasa_array.tolist()\n",
    "# ss\n",
    "ss_array = np.loadtxt(rootpath + 'SS/' + uniprotac + '.ss')\n",
    "if(pos <= window_len - 1):\n",
    "    padding = np.zeros(shape=[window_len-pos+1,3])\n",
    "    ss_array = np.vstack((padding,ss_array[0:pos+window_len]))\n",
    "elif(seq_len - pos < window_len):\n",
    "    padding = np.zeros(shape=[window_len-seq_len+pos,3])\n",
    "    ss_array = np.vstack((ss_array[pos-window_len-1:],padding))\n",
    "else:\n",
    "    ss_array = ss_array[pos-window_len-1:pos+window_len, :]\n",
    "#ss = ss_array.tolist()\n",
    "\n",
    "dataset_feature = dataset_feature.append([{'gene': gene, 'uniprotac': uniprotac, 'variant': variant, 'drug': drug, \n",
    "                                        'smile': smile, 'smile_num':smile_array, 'cactvs_fingerprint': cactvs_fingerprint, 'molecular_weight': molecular_weight, \n",
    "                                        'onehot_before':onehot_before, 'onehot_after':onehot_after, \n",
    "                                        'hhm_before': hhm_before_array, 'hhm_after': hhm_after_array, 'ss': ss_array, 'rasa': rasa_array, \n",
    "                                        'label': label, 'source':source}], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evidence 2: \n",
    "gene = 'MAP2K2'\n",
    "uniprotac = 'P36507'\n",
    "variant = 'V215E'\n",
    "drug = drsp_evidence['drugname'][1]\n",
    "smile = drsp_evidence['smile'][1]\n",
    "smile_num = drsp_evidence['smile_array'][1]\n",
    "cactvs_fingerprint = drsp_evidence['cactvs_fingerprint'][1]\n",
    "molecular_weight = drsp_evidence['molecular_weight'][1]\n",
    "source = 'DRSP'\n",
    "label = 0\n",
    "\n",
    "smile_array = np.zeros(shape=(85,))\n",
    "for j in range(min(85, smile_num.shape[0])):\n",
    "    smile_array[j] = smile_num[j]\n",
    "cactvs_fingerprint = []\n",
    "for strr in cactvs_fingerprint_str:\n",
    "    cactvs_fingerprint.append(fingerprint_dict[strr])\n",
    "cactvs_fingerprint = np.array(cactvs_fingerprint)\n",
    "\n",
    "# sequence features from file\n",
    "pos = int(variant[1:-1])\n",
    "pos_after = variant[-1]\n",
    "\n",
    "# fasta before\n",
    "with open(rootpath + 'fasta/' + uniprotac + '.fasta') as file:\n",
    "    fasta_file = file.readlines()\n",
    "    fasta_full = fasta_file[1]\n",
    "    seq_len = len(fasta_full)\n",
    "    onehot_before = []\n",
    "    if(pos <= window_len - 1):\n",
    "        for j in range(window_len-pos+1): # padding head\n",
    "            onehot_before.append(np.zeros(20))\n",
    "        for strr in fasta_full[0:pos+window_len]:\n",
    "            onehot_before.append(protein_dict[strr])\n",
    "    elif(seq_len - pos < window_len):\n",
    "        for strr in fasta_full[pos-window_len-1:]:\n",
    "            onehot_before.append(protein_dict[strr])\n",
    "        for j in range(window_len-seq_len+pos): # padding end\n",
    "            onehot_before.append(np.zeros(20))\n",
    "    else:        \n",
    "        for strr in fasta_full[pos-window_len-1:pos+window_len]:\n",
    "            onehot_before.append(protein_dict[strr])\n",
    "onehot_before = np.array(onehot_before)\n",
    "\n",
    "# fasta after\n",
    "with open(rootpath + 'fasta/' + uniprotac + '_' + variant + '.fasta') as file:\n",
    "    fasta_file = file.readlines()\n",
    "    fasta_full = fasta_file[1]\n",
    "    #fasta_after = fasta_full[pos-window_len-1:pos+window_len]\n",
    "    onehot_after = []\n",
    "    if(pos <= window_len - 1):\n",
    "        for j in range(window_len-pos+1): # padding head\n",
    "            onehot_after.append(np.zeros(20))\n",
    "        for strr in fasta_full[0:pos+window_len]:\n",
    "            onehot_after.append(protein_dict[strr])\n",
    "    elif(seq_len - pos < window_len):\n",
    "        for strr in fasta_full[pos-window_len-1:]:\n",
    "            onehot_after.append(protein_dict[strr])\n",
    "        for j in range(window_len-seq_len+pos): # padding end\n",
    "            onehot_after.append(np.zeros(20))\n",
    "    else:        \n",
    "        for strr in fasta_full[pos-window_len-1:pos+window_len]:\n",
    "            onehot_after.append(protein_dict[strr])\n",
    "fasta_len = len(fasta_full)\n",
    "onehot_after = np.array(onehot_after)\n",
    "\n",
    "# hhm before\n",
    "with open(rootpath + 'hhm/' + uniprotac + '.hhm') as hhm_file:     \n",
    "    hhm_matrix = np.zeros([fasta_len, 30], float)\n",
    "    hhm_line = hhm_file.readline()\n",
    "    idxx = 0\n",
    "    while(hhm_line[0] != '#'):\n",
    "        hhm_line = hhm_file.readline()\n",
    "    for i in range(0,5):\n",
    "        hhm_line = hhm_file.readline()\n",
    "    while hhm_line:\n",
    "        if(len(hhm_line.split()) == 23):\n",
    "            idxx += 1\n",
    "            if(idxx == fasta_len + 1):\n",
    "                break\n",
    "            each_item = hhm_line.split()[2:22]\n",
    "            for idx, s in enumerate(each_item):\n",
    "                if(s == '*'):\n",
    "                    each_item[idx] = '99999'                            \n",
    "            for j in range(0, 20):\n",
    "                hhm_matrix[idxx - 1, j] = int(each_item[j])\n",
    "                #hhm_matrix[idxx - 1, j] = 10/(1 + math.exp(-1 * int(each_item[j])/2000))                                              \n",
    "        elif(len(hhm_line.split()) == 10):\n",
    "            each_item = hhm_line.split()[0:10]\n",
    "            for idx, s in enumerate(each_item):\n",
    "                if(s == '*'):\n",
    "                    each_item[idx] = '99999'                             \n",
    "            for j in range(20, 30):\n",
    "                hhm_matrix[idxx - 1, j] = int(each_item[j - 20]) \n",
    "                #hhm_matrix[idxx - 1, j] = 10/(1 + math.exp(-1 * int(each_item[j - 20])/2000))                                                               \n",
    "        hhm_line = hhm_file.readline()\n",
    "    if(pos <= window_len - 1):\n",
    "        padding = np.zeros(shape=[window_len-pos+1,30])\n",
    "        hhm_before_array = np.vstack((padding,hhm_matrix[0:pos+window_len, :])) \n",
    "    elif(seq_len - pos < window_len):\n",
    "        padding = np.zeros(shape=[window_len-seq_len+pos,30])\n",
    "        hhm_before_array = np.vstack((hhm_matrix[pos-window_len-1:, :],padding))\n",
    "    else:\n",
    "        hhm_before_array = hhm_matrix[pos-window_len-1:pos+window_len, :]\n",
    "    #hhm_before = hhm_before_array.tolist()\n",
    "\n",
    "# hhm after\n",
    "with open(rootpath + 'hhm/' + uniprotac + '_' + variant + '.hhm') as hhm_file:     \n",
    "    hhm_matrix = np.zeros([fasta_len, 30], float)\n",
    "    hhm_line = hhm_file.readline()\n",
    "    idxx = 0\n",
    "    while(hhm_line[0] != '#'):\n",
    "        hhm_line = hhm_file.readline()\n",
    "    for i in range(0,5):\n",
    "        hhm_line = hhm_file.readline()\n",
    "    while hhm_line:\n",
    "        if(len(hhm_line.split()) == 23):\n",
    "            idxx += 1\n",
    "            if(idxx == fasta_len + 1):\n",
    "                break\n",
    "            each_item = hhm_line.split()[2:22]\n",
    "            for idx, s in enumerate(each_item):\n",
    "                if(s == '*'):\n",
    "                    each_item[idx] = '99999'                            \n",
    "            for j in range(0, 20):\n",
    "                hhm_matrix[idxx - 1, j] = int(each_item[j])\n",
    "                #hhm_matrix[idxx - 1, j] = 10/(1 + math.exp(-1 * int(each_item[j])/2000))                                              \n",
    "        elif(len(hhm_line.split()) == 10):\n",
    "            each_item = hhm_line.split()[0:10]\n",
    "            for idx, s in enumerate(each_item):\n",
    "                if(s == '*'):\n",
    "                    each_item[idx] = '99999'                             \n",
    "            for j in range(20, 30):\n",
    "                hhm_matrix[idxx - 1, j] = int(each_item[j - 20]) \n",
    "                #hhm_matrix[idxx - 1, j] = 10/(1 + math.exp(-1 * int(each_item[j - 20])/2000))                                                                        \n",
    "        hhm_line = hhm_file.readline()\n",
    "    if(pos <= window_len - 1):\n",
    "        padding = np.zeros(shape=[window_len-pos+1,30])\n",
    "        hhm_after_array = np.vstack((padding,hhm_matrix[0:pos+window_len, :])) \n",
    "    elif(seq_len - pos < window_len):\n",
    "        padding = np.zeros(shape=[window_len-seq_len+pos,30])\n",
    "        hhm_after_array = np.vstack((hhm_matrix[pos-window_len-1:, :],padding))\n",
    "    else:\n",
    "        hhm_after_array = hhm_matrix[pos-window_len-1:pos+window_len, :]\n",
    "    #hhm_after = hhm_after_array.tolist()\n",
    "\n",
    "# rasa\n",
    "rasa_array = np.loadtxt(rootpath + 'rASA/' + uniprotac + '.rasa')\n",
    "if(pos <= window_len - 1):\n",
    "    padding = np.zeros(window_len-pos+1)\n",
    "    rasa_array = np.append(padding,rasa_array[0:pos+window_len])\n",
    "elif(seq_len - pos < window_len):\n",
    "    padding = np.zeros(window_len-seq_len+pos)\n",
    "    rasa_array = np.append(rasa_array[pos-window_len-1:],padding)\n",
    "else:\n",
    "    rasa_array = rasa_array[pos-window_len-1:pos+window_len]\n",
    "#rasa = rasa_array.tolist()\n",
    "# ss\n",
    "ss_array = np.loadtxt(rootpath + 'SS/' + uniprotac + '.ss')\n",
    "if(pos <= window_len - 1):\n",
    "    padding = np.zeros(shape=[window_len-pos+1,3])\n",
    "    ss_array = np.vstack((padding,ss_array[0:pos+window_len]))\n",
    "elif(seq_len - pos < window_len):\n",
    "    padding = np.zeros(shape=[window_len-seq_len+pos,3])\n",
    "    ss_array = np.vstack((ss_array[pos-window_len-1:],padding))\n",
    "else:\n",
    "    ss_array = ss_array[pos-window_len-1:pos+window_len, :]\n",
    "#ss = ss_array.tolist()\n",
    "\n",
    "dataset_feature = dataset_feature.append([{'gene': gene, 'uniprotac': uniprotac, 'variant': variant, 'drug': drug, \n",
    "                                        'smile': smile, 'smile_num':smile_array, 'cactvs_fingerprint': cactvs_fingerprint, 'molecular_weight': molecular_weight, \n",
    "                                        'onehot_before':onehot_before, 'onehot_after':onehot_after, \n",
    "                                        'hhm_before': hhm_before_array, 'hhm_after': hhm_after_array, 'ss': ss_array, 'rasa': rasa_array, \n",
    "                                        'label': label, 'source':source}], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evidence 3: \n",
    "gene = 'ROS1'\n",
    "uniprotac = 'P08922'\n",
    "variant = 'G2032R'\n",
    "drug = drsp_evidence['drugname'][2]\n",
    "smile = drsp_evidence['smile'][2]\n",
    "smile_num = drsp_evidence['smile_array'][2]\n",
    "cactvs_fingerprint = drsp_evidence['cactvs_fingerprint'][2]\n",
    "molecular_weight = drsp_evidence['molecular_weight'][2]\n",
    "source = 'DRSP'\n",
    "label = 0\n",
    "\n",
    "smile_array = np.zeros(shape=(85,))\n",
    "for j in range(min(85, smile_num.shape[0])):\n",
    "    smile_array[j] = smile_num[j]\n",
    "cactvs_fingerprint = []\n",
    "for strr in cactvs_fingerprint_str:\n",
    "    cactvs_fingerprint.append(fingerprint_dict[strr])\n",
    "cactvs_fingerprint = np.array(cactvs_fingerprint)\n",
    "\n",
    "# sequence features from file\n",
    "pos = int(variant[1:-1])\n",
    "pos_after = variant[-1]\n",
    "\n",
    "# fasta before\n",
    "with open(rootpath + 'fasta/' + uniprotac + '.fasta') as file:\n",
    "    fasta_file = file.readlines()\n",
    "    fasta_full = fasta_file[1]\n",
    "    seq_len = len(fasta_full)\n",
    "    onehot_before = []\n",
    "    if(pos <= window_len - 1):\n",
    "        for j in range(window_len-pos+1): # padding head\n",
    "            onehot_before.append(np.zeros(20))\n",
    "        for strr in fasta_full[0:pos+window_len]:\n",
    "            onehot_before.append(protein_dict[strr])\n",
    "    elif(seq_len - pos < window_len):\n",
    "        for strr in fasta_full[pos-window_len-1:]:\n",
    "            onehot_before.append(protein_dict[strr])\n",
    "        for j in range(window_len-seq_len+pos): # padding end\n",
    "            onehot_before.append(np.zeros(20))\n",
    "    else:        \n",
    "        for strr in fasta_full[pos-window_len-1:pos+window_len]:\n",
    "            onehot_before.append(protein_dict[strr])\n",
    "onehot_before = np.array(onehot_before)\n",
    "\n",
    "# fasta after\n",
    "with open(rootpath + 'fasta/' + uniprotac + '_' + variant + '.fasta') as file:\n",
    "    fasta_file = file.readlines()\n",
    "    fasta_full = fasta_file[1]\n",
    "    #fasta_after = fasta_full[pos-window_len-1:pos+window_len]\n",
    "    onehot_after = []\n",
    "    if(pos <= window_len - 1):\n",
    "        for j in range(window_len-pos+1): # padding head\n",
    "            onehot_after.append(np.zeros(20))\n",
    "        for strr in fasta_full[0:pos+window_len]:\n",
    "            onehot_after.append(protein_dict[strr])\n",
    "    elif(seq_len - pos < window_len):\n",
    "        for strr in fasta_full[pos-window_len-1:]:\n",
    "            onehot_after.append(protein_dict[strr])\n",
    "        for j in range(window_len-seq_len+pos): # padding end\n",
    "            onehot_after.append(np.zeros(20))\n",
    "    else:        \n",
    "        for strr in fasta_full[pos-window_len-1:pos+window_len]:\n",
    "            onehot_after.append(protein_dict[strr])\n",
    "fasta_len = len(fasta_full)\n",
    "onehot_after = np.array(onehot_after)\n",
    "\n",
    "# hhm before\n",
    "with open(rootpath + 'hhm/' + uniprotac + '.hhm') as hhm_file:     \n",
    "    hhm_matrix = np.zeros([fasta_len, 30], float)\n",
    "    hhm_line = hhm_file.readline()\n",
    "    idxx = 0\n",
    "    while(hhm_line[0] != '#'):\n",
    "        hhm_line = hhm_file.readline()\n",
    "    for i in range(0,5):\n",
    "        hhm_line = hhm_file.readline()\n",
    "    while hhm_line:\n",
    "        if(len(hhm_line.split()) == 23):\n",
    "            idxx += 1\n",
    "            if(idxx == fasta_len + 1):\n",
    "                break\n",
    "            each_item = hhm_line.split()[2:22]\n",
    "            for idx, s in enumerate(each_item):\n",
    "                if(s == '*'):\n",
    "                    each_item[idx] = '99999'                            \n",
    "            for j in range(0, 20):\n",
    "                hhm_matrix[idxx - 1, j] = int(each_item[j])\n",
    "                #hhm_matrix[idxx - 1, j] = 10/(1 + math.exp(-1 * int(each_item[j])/2000))                                              \n",
    "        elif(len(hhm_line.split()) == 10):\n",
    "            each_item = hhm_line.split()[0:10]\n",
    "            for idx, s in enumerate(each_item):\n",
    "                if(s == '*'):\n",
    "                    each_item[idx] = '99999'                             \n",
    "            for j in range(20, 30):\n",
    "                hhm_matrix[idxx - 1, j] = int(each_item[j - 20]) \n",
    "                #hhm_matrix[idxx - 1, j] = 10/(1 + math.exp(-1 * int(each_item[j - 20])/2000))                                                               \n",
    "        hhm_line = hhm_file.readline()\n",
    "    if(pos <= window_len - 1):\n",
    "        padding = np.zeros(shape=[window_len-pos+1,30])\n",
    "        hhm_before_array = np.vstack((padding,hhm_matrix[0:pos+window_len, :])) \n",
    "    elif(seq_len - pos < window_len):\n",
    "        padding = np.zeros(shape=[window_len-seq_len+pos,30])\n",
    "        hhm_before_array = np.vstack((hhm_matrix[pos-window_len-1:, :],padding))\n",
    "    else:\n",
    "        hhm_before_array = hhm_matrix[pos-window_len-1:pos+window_len, :]\n",
    "    #hhm_before = hhm_before_array.tolist()\n",
    "\n",
    "# hhm after\n",
    "with open(rootpath + 'hhm/' + uniprotac + '_' + variant + '.hhm') as hhm_file:     \n",
    "    hhm_matrix = np.zeros([fasta_len, 30], float)\n",
    "    hhm_line = hhm_file.readline()\n",
    "    idxx = 0\n",
    "    while(hhm_line[0] != '#'):\n",
    "        hhm_line = hhm_file.readline()\n",
    "    for i in range(0,5):\n",
    "        hhm_line = hhm_file.readline()\n",
    "    while hhm_line:\n",
    "        if(len(hhm_line.split()) == 23):\n",
    "            idxx += 1\n",
    "            if(idxx == fasta_len + 1):\n",
    "                break\n",
    "            each_item = hhm_line.split()[2:22]\n",
    "            for idx, s in enumerate(each_item):\n",
    "                if(s == '*'):\n",
    "                    each_item[idx] = '99999'                            \n",
    "            for j in range(0, 20):\n",
    "                hhm_matrix[idxx - 1, j] = int(each_item[j])\n",
    "                #hhm_matrix[idxx - 1, j] = 10/(1 + math.exp(-1 * int(each_item[j])/2000))                                              \n",
    "        elif(len(hhm_line.split()) == 10):\n",
    "            each_item = hhm_line.split()[0:10]\n",
    "            for idx, s in enumerate(each_item):\n",
    "                if(s == '*'):\n",
    "                    each_item[idx] = '99999'                             \n",
    "            for j in range(20, 30):\n",
    "                hhm_matrix[idxx - 1, j] = int(each_item[j - 20]) \n",
    "                #hhm_matrix[idxx - 1, j] = 10/(1 + math.exp(-1 * int(each_item[j - 20])/2000))                                                                        \n",
    "        hhm_line = hhm_file.readline()\n",
    "    if(pos <= window_len - 1):\n",
    "        padding = np.zeros(shape=[window_len-pos+1,30])\n",
    "        hhm_after_array = np.vstack((padding,hhm_matrix[0:pos+window_len, :])) \n",
    "    elif(seq_len - pos < window_len):\n",
    "        padding = np.zeros(shape=[window_len-seq_len+pos,30])\n",
    "        hhm_after_array = np.vstack((hhm_matrix[pos-window_len-1:, :],padding))\n",
    "    else:\n",
    "        hhm_after_array = hhm_matrix[pos-window_len-1:pos+window_len, :]\n",
    "    #hhm_after = hhm_after_array.tolist()\n",
    "\n",
    "# rasa\n",
    "rasa_array = np.loadtxt(rootpath + 'rASA/' + uniprotac + '.rasa')\n",
    "if(pos <= window_len - 1):\n",
    "    padding = np.zeros(window_len-pos+1)\n",
    "    rasa_array = np.append(padding,rasa_array[0:pos+window_len])\n",
    "elif(seq_len - pos < window_len):\n",
    "    padding = np.zeros(window_len-seq_len+pos)\n",
    "    rasa_array = np.append(rasa_array[pos-window_len-1:],padding)\n",
    "else:\n",
    "    rasa_array = rasa_array[pos-window_len-1:pos+window_len]\n",
    "#rasa = rasa_array.tolist()\n",
    "# ss\n",
    "ss_array = np.loadtxt(rootpath + 'SS/' + uniprotac + '.ss')\n",
    "if(pos <= window_len - 1):\n",
    "    padding = np.zeros(shape=[window_len-pos+1,3])\n",
    "    ss_array = np.vstack((padding,ss_array[0:pos+window_len]))\n",
    "elif(seq_len - pos < window_len):\n",
    "    padding = np.zeros(shape=[window_len-seq_len+pos,3])\n",
    "    ss_array = np.vstack((ss_array[pos-window_len-1:],padding))\n",
    "else:\n",
    "    ss_array = ss_array[pos-window_len-1:pos+window_len, :]\n",
    "#ss = ss_array.tolist()\n",
    "\n",
    "dataset_feature = dataset_feature.append([{'gene': gene, 'uniprotac': uniprotac, 'variant': variant, 'drug': drug, \n",
    "                                        'smile': smile, 'smile_num':smile_array, 'cactvs_fingerprint': cactvs_fingerprint, 'molecular_weight': molecular_weight, \n",
    "                                        'onehot_before':onehot_before, 'onehot_after':onehot_after, \n",
    "                                        'hhm_before': hhm_before_array, 'hhm_after': hhm_after_array, 'ss': ss_array, 'rasa': rasa_array, \n",
    "                                        'label': label, 'source':source}], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gene</th>\n",
       "      <th>uniprotac</th>\n",
       "      <th>variant</th>\n",
       "      <th>drug</th>\n",
       "      <th>smile</th>\n",
       "      <th>smile_num</th>\n",
       "      <th>cactvs_fingerprint</th>\n",
       "      <th>molecular_weight</th>\n",
       "      <th>onehot_before</th>\n",
       "      <th>onehot_after</th>\n",
       "      <th>hhm_before</th>\n",
       "      <th>hhm_after</th>\n",
       "      <th>ss</th>\n",
       "      <th>rasa</th>\n",
       "      <th>label</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BRAF</td>\n",
       "      <td>P15056</td>\n",
       "      <td>L505H</td>\n",
       "      <td>vemurafenib</td>\n",
       "      <td>CCCS(=O)(=O)NC1=C(C(=C(C=C1)F)C(=O)C2=CNC3=C2C...</td>\n",
       "      <td>[42.0, 42.0, 42.0, 49.0, 1.0, 40.0, 48.0, 31.0...</td>\n",
       "      <td>[1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, ...</td>\n",
       "      <td>489.90</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>[[4985.0, 6446.0, 4990.0, 3375.0, 5454.0, 5675...</td>\n",
       "      <td>[[4975.0, 6741.0, 5123.0, 3372.0, 5453.0, 5641...</td>\n",
       "      <td>[[0.0, 1.0, 0.0], [0.0, 0.0, 1.0], [0.0, 0.0, ...</td>\n",
       "      <td>[0.449, 0.182, 0.768, 0.375, 0.285, 0.0, 0.085...</td>\n",
       "      <td>0</td>\n",
       "      <td>DRSP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MAP2K2</td>\n",
       "      <td>P36507</td>\n",
       "      <td>V215E</td>\n",
       "      <td>PD0325901</td>\n",
       "      <td>C1=CC(=C(C=C1I)F)NC2=C(C=CC(=C2F)F)C(=O)NOC[C@...</td>\n",
       "      <td>[42.0, 35.0, 40.0, 42.0, 42.0, 1.0, 40.0, 42.0...</td>\n",
       "      <td>[1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, ...</td>\n",
       "      <td>482.19</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>[[5049.0, 6722.0, 7112.0, 5144.0, 7659.0, 6624...</td>\n",
       "      <td>[[5118.0, 7134.0, 6991.0, 5129.0, 7256.0, 7172...</td>\n",
       "      <td>[[1.0, 0.0, 0.0], [1.0, 0.0, 0.0], [1.0, 0.0, ...</td>\n",
       "      <td>[0.274, 0.502, 0.432, 0.156, 0.64, 0.102, 0.19...</td>\n",
       "      <td>0</td>\n",
       "      <td>DRSP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ROS1</td>\n",
       "      <td>P08922</td>\n",
       "      <td>G2032R</td>\n",
       "      <td>crizotinib</td>\n",
       "      <td>C[C@H](C1=C(C=CC(=C1Cl)F)Cl)OC2=C(N=CC(=C2)C3=...</td>\n",
       "      <td>[42.0, 53.0, 42.0, 8.0, 12.0, 54.0, 1.0, 42.0,...</td>\n",
       "      <td>[1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, ...</td>\n",
       "      <td>450.30</td>\n",
       "      <td>[[0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>[[0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>[[3071.0, 6101.0, 5203.0, 4504.0, 6802.0, 4387...</td>\n",
       "      <td>[[3023.0, 6237.0, 5214.0, 4457.0, 6729.0, 4350...</td>\n",
       "      <td>[[1.0, 0.0, 0.0], [1.0, 0.0, 0.0], [0.0, 0.0, ...</td>\n",
       "      <td>[0.335, 0.369, 0.046, 0.61, 0.156, 0.491, 0.02...</td>\n",
       "      <td>0</td>\n",
       "      <td>DRSP</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     gene uniprotac variant         drug  \\\n",
       "0    BRAF    P15056   L505H  vemurafenib   \n",
       "1  MAP2K2    P36507   V215E    PD0325901   \n",
       "2    ROS1    P08922  G2032R   crizotinib   \n",
       "\n",
       "                                               smile  \\\n",
       "0  CCCS(=O)(=O)NC1=C(C(=C(C=C1)F)C(=O)C2=CNC3=C2C...   \n",
       "1  C1=CC(=C(C=C1I)F)NC2=C(C=CC(=C2F)F)C(=O)NOC[C@...   \n",
       "2  C[C@H](C1=C(C=CC(=C1Cl)F)Cl)OC2=C(N=CC(=C2)C3=...   \n",
       "\n",
       "                                           smile_num  \\\n",
       "0  [42.0, 42.0, 42.0, 49.0, 1.0, 40.0, 48.0, 31.0...   \n",
       "1  [42.0, 35.0, 40.0, 42.0, 42.0, 1.0, 40.0, 42.0...   \n",
       "2  [42.0, 53.0, 42.0, 8.0, 12.0, 54.0, 1.0, 42.0,...   \n",
       "\n",
       "                                  cactvs_fingerprint  molecular_weight  \\\n",
       "0  [1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, ...            489.90   \n",
       "1  [1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, ...            482.19   \n",
       "2  [1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, ...            450.30   \n",
       "\n",
       "                                       onehot_before  \\\n",
       "0  [[0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0,...   \n",
       "1  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...   \n",
       "2  [[0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...   \n",
       "\n",
       "                                        onehot_after  \\\n",
       "0  [[0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0,...   \n",
       "1  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...   \n",
       "2  [[0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...   \n",
       "\n",
       "                                          hhm_before  \\\n",
       "0  [[4985.0, 6446.0, 4990.0, 3375.0, 5454.0, 5675...   \n",
       "1  [[5049.0, 6722.0, 7112.0, 5144.0, 7659.0, 6624...   \n",
       "2  [[3071.0, 6101.0, 5203.0, 4504.0, 6802.0, 4387...   \n",
       "\n",
       "                                           hhm_after  \\\n",
       "0  [[4975.0, 6741.0, 5123.0, 3372.0, 5453.0, 5641...   \n",
       "1  [[5118.0, 7134.0, 6991.0, 5129.0, 7256.0, 7172...   \n",
       "2  [[3023.0, 6237.0, 5214.0, 4457.0, 6729.0, 4350...   \n",
       "\n",
       "                                                  ss  \\\n",
       "0  [[0.0, 1.0, 0.0], [0.0, 0.0, 1.0], [0.0, 0.0, ...   \n",
       "1  [[1.0, 0.0, 0.0], [1.0, 0.0, 0.0], [1.0, 0.0, ...   \n",
       "2  [[1.0, 0.0, 0.0], [1.0, 0.0, 0.0], [0.0, 0.0, ...   \n",
       "\n",
       "                                                rasa label source  \n",
       "0  [0.449, 0.182, 0.768, 0.375, 0.285, 0.0, 0.085...     0   DRSP  \n",
       "1  [0.274, 0.502, 0.432, 0.156, 0.64, 0.102, 0.19...     0   DRSP  \n",
       "2  [0.335, 0.369, 0.046, 0.61, 0.156, 0.491, 0.02...     0   DRSP  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 16)\n",
      "     gene uniprotac variant         drug  \\\n",
      "0    BRAF    P15056   L505H  vemurafenib   \n",
      "1  MAP2K2    P36507   V215E    PD0325901   \n",
      "2    ROS1    P08922  G2032R   crizotinib   \n",
      "\n",
      "                                               smile  \\\n",
      "0  CCCS(=O)(=O)NC1=C(C(=C(C=C1)F)C(=O)C2=CNC3=C2C...   \n",
      "1  C1=CC(=C(C=C1I)F)NC2=C(C=CC(=C2F)F)C(=O)NOC[C@...   \n",
      "2  C[C@H](C1=C(C=CC(=C1Cl)F)Cl)OC2=C(N=CC(=C2)C3=...   \n",
      "\n",
      "                                           smile_num  \\\n",
      "0  [42.0, 42.0, 42.0, 49.0, 1.0, 40.0, 48.0, 31.0...   \n",
      "1  [42.0, 35.0, 40.0, 42.0, 42.0, 1.0, 40.0, 42.0...   \n",
      "2  [42.0, 53.0, 42.0, 8.0, 12.0, 54.0, 1.0, 42.0,...   \n",
      "\n",
      "                                  cactvs_fingerprint  molecular_weight  \\\n",
      "0  [1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, ...            489.90   \n",
      "1  [1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, ...            482.19   \n",
      "2  [1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, ...            450.30   \n",
      "\n",
      "                                       onehot_before  \\\n",
      "0  [[0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0,...   \n",
      "1  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...   \n",
      "2  [[0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...   \n",
      "\n",
      "                                        onehot_after  \\\n",
      "0  [[0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0,...   \n",
      "1  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...   \n",
      "2  [[0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...   \n",
      "\n",
      "                                          hhm_before  \\\n",
      "0  [[4985.0, 6446.0, 4990.0, 3375.0, 5454.0, 5675...   \n",
      "1  [[5049.0, 6722.0, 7112.0, 5144.0, 7659.0, 6624...   \n",
      "2  [[3071.0, 6101.0, 5203.0, 4504.0, 6802.0, 4387...   \n",
      "\n",
      "                                           hhm_after  \\\n",
      "0  [[4975.0, 6741.0, 5123.0, 3372.0, 5453.0, 5641...   \n",
      "1  [[5118.0, 7134.0, 6991.0, 5129.0, 7256.0, 7172...   \n",
      "2  [[3023.0, 6237.0, 5214.0, 4457.0, 6729.0, 4350...   \n",
      "\n",
      "                                                  ss  \\\n",
      "0  [[0.0, 1.0, 0.0], [0.0, 0.0, 1.0], [0.0, 0.0, ...   \n",
      "1  [[1.0, 0.0, 0.0], [1.0, 0.0, 0.0], [1.0, 0.0, ...   \n",
      "2  [[1.0, 0.0, 0.0], [1.0, 0.0, 0.0], [0.0, 0.0, ...   \n",
      "\n",
      "                                                rasa label source  \n",
      "0  [0.449, 0.182, 0.768, 0.375, 0.285, 0.0, 0.085...     0   DRSP  \n",
      "1  [0.274, 0.502, 0.432, 0.156, 0.64, 0.102, 0.19...     0   DRSP  \n",
      "2  [0.335, 0.369, 0.046, 0.61, 0.156, 0.491, 0.02...     0   DRSP  \n"
     ]
    }
   ],
   "source": [
    "print(dataset_feature.shape)\n",
    "print(dataset_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_feature.to_pickle(rootpath + 'drsp_dataset_featurecode.dataset')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6fff98fc3b3d81bd655c2cc48858186e4d9e2db7b515bf1c3221888f12a62f87"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
